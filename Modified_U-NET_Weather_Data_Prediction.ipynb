{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"Modified_U-NET_Weather_Data_Prediction_(processed_labels).ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"M-SiHFStw1gN","colab_type":"text"},"source":["## **Modified-Unet**\n","\n","The model in this code is inspired by the U-Net model proposed by Ronneberger et. al. with modifications to Depth, Regularization and Hyperparameters."]},{"cell_type":"code","metadata":{"id":"X2vwGBzSUhC_","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9NN5jwT671Z8","colab_type":"code","colab":{}},"source":["!pip install h5py pyyaml"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B4L_2lstUY4a","colab_type":"code","colab":{}},"source":["# Importing the necessary libraries and API's\n","\n","import numpy as np \n","from numpy import asarray\n","import tensorflow as tf \n","from tensorflow.keras.optimizers import Adam,RMSprop,SGD\n","import os\n","import shutil \n","import matplotlib.pyplot as plt \n","import matplotlib.image as mpimg\n","from mpl_toolkits.axes_grid1 import ImageGrid\n","from PIL import Image\n","import keras\n","from tensorflow.keras.models import Model, load_model\n","import tensorflow.keras.layers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EhuKS3N0UY4m","colab_type":"code","colab":{}},"source":["# Creating variables for training and labels directory\n","data_directory = r'/content/drive/My Drive/weather_news'\n","training_dir = r'/content/drive/My Drive/weather_news/train_images'\n","label_dir = r'/content/drive/My Drive/weather_news/LabelboxAnnotations'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PXT7qS4mUY4u","colab_type":"code","colab":{}},"source":["# converting directory images into a list\n","train_list = os.listdir(training_dir)\n","label_list = os.listdir(label_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BMcGc4rsUY41","colab_type":"code","colab":{}},"source":["# checking the length of the training and label directory \n","print(len(train_list))\n","print(len(label_list))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GnBTbrzPUY49","colab_type":"code","colab":{}},"source":["# We see that the label_list has some unnecessary segmentation labels not matching with the images in the training directory and hence wee need to remove them before training \n","\n","unwanted = []\n","train = []\n","label = []\n","\n","for x in train_list:\n","    train.append(x[0:8])\n","    \n","for x in label_list:\n","    label.append(x[0:8])\n","    \n","for x in label:\n","    if x not in train:\n","        unwanted.append(x)\n","\n","for x in unwanted:\n","    x = x + \".png\"\n","    label_list.remove(x)\n","\n","print(len(unwanted))\n","print(len(label_list))\n","print(len(train_list))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fPSR0Vy_UY5U","colab_type":"code","colab":{}},"source":["# creating the numpy arrays for the images and the corresponding segmentation labels \n","\n","height , width = (160,160)\n","m = len(label_list)\n","X = np.zeros([m, height, width, 3])\n","Y_init = np.zeros([m, height, width, 4])\n","\n","for i in range(m):\n","    X[i] = mpimg.imread(training_dir + \"/\" + train_list[i])\n","    Y_init[i] = mpimg.imread(label_dir + \"/\" + label_list[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kq-i9xC_UY5Y","colab_type":"code","colab":{}},"source":["# color_list is actually a dictionary that contains the pixel valus across the channels for the four segmentation colors. While carrying out training for the segmentation labels we need the labels \n","# to be 1 or 0 across the channels .In order to do so we need to convert the color pixels into binary values before training and convert the predicted maps into corresponding color pixels after prediction.\n","# Hence we need the color_list dictionary to carry out such conversions.\n","\n","color_list = {}\n","\n","color_list['blue'] = (0.0117647061124444, 0.6078431606292725, 0.8980392217636108, 1.0)\n","color_list['yellow'] = (0.8941176533699036, 0.7686274647712708, 0.2549019753932953, 1.0)\n","color_list['green'] = (0.3803921639919281, 0.3803921639919281, 0.3803921639919281, 1.0)\n","color_list['purple'] = (0.5568627715110779, 0.1411764770746231, 0.6666666865348816, 1.0)\n","color_list['white'] = (1.0, 1.0, 1.0, 1.0)\n","color_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RHnHZ09lUY5b","colab_type":"code","colab":{}},"source":["# label_preprocess function converts the color segmentaion maaps into binary along the channels acros the height and width of the segmentation labels.\n","# If the segentation labels of your data are already in binary then you dont need to use this function.\n","\n","def label_preprocess(Y_init,num_images,height,width,channels,color_list):\n","      \n","    Y = np.zeros([num_images,height,width,channels])\n","\n","    for n in range(num_images):\n","        for i in range(height):\n","            for j in range(width):\n","                t = tuple(Y_init[n,i,j,:])\n","        \n","                if t == color_list['blue']:\n","                    Y[n,i,j,:] = np.array((1,0,0,0))\n","                elif t == color_list['yellow']:\n","                    Y[n,i,j,:] = np.array((0,1,0,0))\n","                elif t == color_list['green']:\n","                    Y[n,i,j,:] = np.array((0,0,1,0))\n","                elif t == color_list['white']:\n","                    Y[n,i,j,:] = np.array((1,1,1,1))\n","                elif t == color_list['purple']:\n","                    Y[n,i,j,:] = np.array((0,0,0,1))\n","                    \n","    return Y  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"12zSb0CqUY5h","colab_type":"code","colab":{}},"source":["# This function is used to predict the segmentation output for images \n","\n","def predictions(trained_model,test_dir,num_images,height,width,channels,color_list):\n","    \n","    y = np.zeros([num_images,height,width,channels])\n","    x = np.zeros([num_images,height,width,channels])\n","    \n","    for i in range(len(test_list)):\n","        x[i] = mpimg.imread(test_dir + '/' + test_list[i])\n","        y[i] = trained_model.predict(np.expand_dims(x[i], axis = 0))\n","    \n","    Y_final = prediction_postprocess(y,num_images,height,width,channels,color_list)\n","    \n","    for i in range(Y_final.shape[0]):\n","        plt.imshow(Y[i])\n","        plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2AT2nDn-eGQI","colab_type":"code","colab":{}},"source":["# Calculation of intersection over union of predicted segmentations\n","\n","def Mean_IoU(Y_pred , Y, smooth = 1):\n","    \n","    I_Area = tf.keras.backend.sum(tf.keras.backend.abs(np.multiply(Y_pred,Y)), axis = [1,2,3])\n","    U_Area = tf.keras.backend.sum(Y_pred, axis = [1,2,3]) + tf.keras.backend.sum(Y, axis = [1,2,3]) - I_Area\n","    IoU_value = I_Area/U_Area\n","    \n","    m = Y.shape[0]\n","    for i in range(m):   \n","        print(\"IoU of Image \" + str(i+1) + \" = \" + str(IoU_value[i]))\n","        \n","    mean_IoU = tf.keras.backend.mean((I_Area + smooth)/(U_Area + smooth), axis = 0) \n","    \n","    return mean_IoU"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4QlUviz8EyuB","colab_type":"code","colab":{}},"source":["# Calculation of intersection over union of predicted segmentations\n","\n","def IoU(Y_pred , Y, smooth = 1):\n","    \n","    I_Area = tf.keras.backend.sum(tf.keras.backend.abs(np.multiply(Y_pred,Y)), axis = [1,2,3])\n","    U_Area = tf.keras.backend.sum(Y_pred, axis = [1,2,3]) + tf.keras.backend.sum(Y, axis = [1,2,3]) - I_Area\n","    IoU_value = I_Area/U_Area \n","    \n","    return IoU_value"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XT144SM5UY5e","colab_type":"code","colab":{}},"source":["# Before giving the final predicted map the image is processed to yield the segmentation in the four segmentation colors\n","\n","def prediction_postprocess(trained_model,test_directory,test_labels,num_images,height,width,channel,color_list):\n","    \n","    Y_pred = np.zeros([num_images,height,width,channel])\n","    Y_init_pred = np.zeros([num_images,height,width,channel])\n","    test_list = os.listdir(test_directory)\n","    axis_image = plt.figure(figsize = (160,160))\n","\n","\n","    \n","    for n in range(num_images):\n","\n","      image = mpimg.imread(test_directory + '/' + test_list[n])\n","      Y_init_pred[n,:,:,:] = trained_model.predict(np.expand_dims(image, axis = 0))\n","\n","      for i in range(height):\n","        for j in range(width):\n","\n","          ch = np.argmax(Y_init_pred[n,i,j,:])\n","\n","          if ch == 0:\n","            Y_pred[n,i,j,:] = np.array(color_list['blue'])\n","          elif ch == 1:\n","            Y_pred[n,i,j,:] = np.array(color_list['yellow'])\n","          elif ch == 2:\n","            Y_pred[n,i,j,:] = np.array(color_list['green'])\n","          elif ch == 3:\n","            Y_pred[n,i,j,:] = np.array(color_list['purple'])\n","\n","      fig = plt.figure(figsize = (50,50))\n","      grid = ImageGrid(fig, 111, nrows_ncols = (1,2), axes_pad = 0.1)\n","\n","      for ax, im in zip(grid, [image, np.squeeze(Y_pred[n])]):\n","        ax.imshow(im)\n","        ax.set_title(IoU(np.expand_dims(test_labels[n], axis=0), np.expand_dims(Y_init_pred[n], axis=0)).numpy())\n","      plt.savefig('/content/drive/My Drive/weather_news/model_unet_processed/Test_Predictions/Image' + str(n))\n","      plt.show()\n","     \n","    return Y_pred   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ouNuMw8-UY5k","colab_type":"code","colab":{}},"source":["# Function for a single resolution convolution operations\n","\n","def conv_layer(input_layer, conv_channels, kernel_size = (3,3), pool_stride = (2,2), dropout_rate = 0.2, padding = 'same', activation = 'relu'):        \n","    \n","    layer_1 = tf.keras.layers.Conv2D(conv_channels, kernel_size, activation = activation, padding = padding, kernel_initializer = 'he_normal')(input_layer)\n","    layer_2 = tf.keras.layers.BatchNormalization()(layer_1)\n","    layer_3 = tf.keras.layers.Dropout(dropout_rate)(layer_2)\n","    layer_4 = tf.keras.layers.Conv2D(conv_channels, kernel_size, activation = activation, padding = padding, kernel_initializer = 'he_normal')(layer_3)\n","    layer_5 = tf.keras.layers.BatchNormalization()(layer_4)\n","    layer_6 = tf.keras.layers.MaxPool2D(pool_stride)(layer_5)\n","    \n","    return layer_1,layer_6"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-qdmZkUQUY5n","colab_type":"code","colab":{}},"source":["# Function for a single resolution convolution operation at the terminal position\n","\n","def terminal_conv_layer(input_layer, conv_channels, kernel_size = (3,3), dropout_rate = 0.2, padding = 'same', activation = 'relu'):\n","    \n","    layer_1 = tf.keras.layers.Conv2D(conv_channels, kernel_size, activation = activation, padding = padding, kernel_initializer = 'he_normal')(input_layer)\n","    layer_2 = tf.keras.layers.BatchNormalization()(layer_1)\n","    layer_3 = tf.keras.layers.Dropout(dropout_rate)(layer_2)\n","    layer_4 = tf.keras.layers.Conv2D(conv_channels, kernel_size, activation = activation, padding = padding, kernel_initializer = 'he_normal')(layer_3)\n","    layer_5 = tf.keras.layers.BatchNormalization()(layer_4)\n","    \n","    return layer_5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zqDG3Eg-UY5q","colab_type":"code","colab":{}},"source":["# Function for a single resolution transpose convolution operation\n","\n","def transpose_conv_layer(input_layer, skip_layer, conv_channels, kernel_size = (3,3), transpose_kernel_size = (2,2), dropout_rate = 0.2, padding = 'same', activation = 'relu', transpose_strides = (2,2)):\n","    \n","    layer_1 = tf.keras.layers.Conv2DTranspose(conv_channels, transpose_kernel_size, strides = transpose_strides, padding = padding )(input_layer)\n","    layer_2 = tf.keras.layers.concatenate([layer_1, skip_layer], axis = 3)\n","    \n","    layer_3 = tf.keras.layers.Conv2D(conv_channels, kernel_size, activation = activation, padding = padding, kernel_initializer = 'he_normal')(layer_2)\n","    layer_4 = tf.keras.layers.BatchNormalization()(layer_3)\n","    layer_5 = tf.keras.layers.Dropout(dropout_rate)(layer_4)\n","    layer_6 = tf.keras.layers.Conv2D(conv_channels, kernel_size, activation = activation, padding = padding, kernel_initializer = 'he_normal')(layer_5)\n","    layer_7 = tf.keras.layers.BatchNormalization()(layer_6)    \n","    \n","    return layer_7"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SGzbdEy_UY5s","colab_type":"code","colab":{}},"source":["# The final U-Net model of this program\n","\n","def modified_unet_model(height, width, image_channels):\n","    \n","    inputs = tf.keras.layers.Input((height, width, image_channels))\n","    normalized_inputs = tf.keras.layers.Lambda(lambda x: x/255)(inputs)\n","\n","    S1,D1 = conv_layer(normalized_inputs, 16)\n","    S2,D2 = conv_layer(D1, 32)\n","    S3,D3 = conv_layer(D2, 64)\n","    S4,D4 = conv_layer(D3, 128)\n","    S5,D5 = conv_layer(D4, 256)\n","\n","    T1 = terminal_conv_layer(D5, 512)\n","\n","    U1 = transpose_conv_layer(T1, S5, 256)\n","    U2 = transpose_conv_layer(U1, S4, 128)\n","    U3 = transpose_conv_layer(U2, S3, 64)\n","    U4 = transpose_conv_layer(U3, S2, 32)\n","    U5 = transpose_conv_layer(U4, S1, 16)\n","\n","    outputs = tf.keras.layers.Conv2D(4,(1,1), activation = 'sigmoid')(U5)\n","\n","    model = Model(inputs = [inputs], outputs = [outputs])\n","    \n","    model.summary()\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FNYybVFAUY5u","colab_type":"code","colab":{}},"source":["# This function creates an instance of the model and compiles it with the entered optimizers, loss criterion and metrics and prints the summary of the model\n","\n","def model_construction(X,Y,optimizer,loss,metrics):\n","    \n","    h = X.shape[1]\n","    w = X.shape[2]\n","    c = X.shape[3]\n","    \n","    unet_model = modified_unet_model(h,w,c)\n","    \n","    unet_model.compile(optimizer = optimizer, loss = loss, metrics = [metrics])\n","    unet_model.summary()\n","    \n","    return unet_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XZunEte4glLr","colab_type":"code","colab":{}},"source":["# loading the earlier trained model\n","\n","filepath = '/content/drive/My Drive/weather_news/model_unet_processed/Trained_Model'\n","trained_model = keras.models.load_model(filepath)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5u0ph2KLUY5y","colab_type":"code","colab":{}},"source":["# processing the training image labels before training\n","Y = label_preprocess(Y_init,m,height,width,4,color_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MjpuHv1VzMcT","colab_type":"code","colab":{}},"source":["# Predictions for calculating the mean IoU\n","\n","Y_pred_init = trained_model.predict(X)\n","Y_prediction = np.zeros([X.shape[0],height,width,4]) \n","\n","for n in range(X.shape[0]):\n","  for i in range(height):\n","    for j in range(width):\n","\n","      ch = np.argmax(Y_pred_init[n,i,j,:])\n","\n","      if ch == 0:\n","        Y_prediction[n,i,j,:] = np.array((1,0,0,0))\n","      elif ch == 1:\n","        Y_prediction[n,i,j,:] = np.array((0,1,0,0))\n","      elif ch == 2:\n","        Y_prediction[n,i,j,:] = np.array((0,0,1,0))\n","      elif ch == 3:\n","        Y_prediction[n,i,j,:] = np.array((0,0,0,1))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rpRu5o24BTWE","colab_type":"code","colab":{}},"source":["# mean IoU calculations\n","\n","mean_iou = Mean_IoU(Y_prediction,Y)\n","print(\"\\n\\n Mean intersection over Union is \" + str(mean_iou*100) )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l1sJKQrMUY52","colab_type":"code","colab":{}},"source":["# predictions over train images\n","prediction_postprocess(trained_model,training_dir,Y,len(os.listdir(training_dir)),160,160,4,color_list)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fiLWMKxyYjx3","colab_type":"text"},"source":["## **Further Training**\n","\n","If wished one can further train the model here by changing the file path to the place where the latest parameters are saved and further save the whole model in the desired directory by changing the path in the \"trained_model.save\" line."]},{"cell_type":"code","metadata":{"id":"tojxIDT3v0M9","colab_type":"code","colab":{}},"source":["checkpoint_filepath = '/content/drive/My Drive/weather_news/model_unet_processed/checkpoint'\n","\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath,\n","                                                               save_weights_only = True,\n","                                                               verbose = 1,\n","                                                               save_freq = 10\n","                                                               )\n","history = trained_model.fit(X,Y,epochs = 10, validation_split = 0.01, callbacks = [model_checkpoint_callback], verbose = 2)\n","trained_model.save('/content/drive/My Drive/weather_news/model_unet_processed')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6XsG7Erte_B4","colab_type":"code","colab":{}},"source":["checkpoint_filepath = '/content/drive/My Drive/weather_news/model_unet_processed/checkpoint'\n","\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath,\n","                                                               save_weights_only = True,\n","                                                               verbose = 1,\n","                                                               save_freq = 10\n","                                                               )\n","\n","checkpoint_directory = os.path.dirname(checkpoint_filepath)\n","\n","trained_model_ = model_construction(X,Y,'sgd','binary_crossentropy','acc')\n","latest = tf.train.latest_checkpoint(checkpoint_directory)\n","trained_model.load_weights(latest)\n","history = trained_model.fit(X,Y,epochs = 10, validation_split = 0.01, callbacks = [model_checkpoint_callback], verbose = 2)\n","trained_model.save('/content/drive/My Drive/weather_news/model_unet_processed')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FoICfoonBojl","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}